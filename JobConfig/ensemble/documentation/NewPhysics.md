## ðŸ§ª Bash Script Documentation: Introducing New Physics `Stage3_addsignal.sh`

### **1. Overview**

The `Stage3_addsignal.sh` script is designed for **signal injection and mixing** to create multiple "pseudo-experiment" datasets. This allows physicists to test reconstruction and analysis techniques under specific signal hypotheses without running full-scale, expensive simulations for every $R_{\mu e}$ rate.

| Component | Description |
| :--- | :--- |
| **Purpose** | To combine a pre-existing background ensemble (the `KNOWN` sample from Stage 2) with a statistically relevant amount of the signal (`SIGNAL`) at a chosen conversion rate (`RATE`). This mixing is done for `NEXP` independent trials. |
| **Prerequisites** | Requires the configuration file (`.txt`) and data files (`mcs` and `nts`) from a completed Stage 2 ensemble production. Requires `calculateEvents.py`, `mu2e` job tools, and SAM tools (`samDatasetsSummary.sh`, `mu2eDatasetFileList`). |
| **Outcome** | `NEXP` sets of output files (`nts` Ntuples) where background events are randomly mixed with a Poisson-sampled quantity of signal events.  |

### **2. Usage**

The script requires a known background tag, a signal name, and a conversion rate.

```bash
Stage3_addsignal.sh --known <MDS_TAG> --signal <SIGNAL_NAME> --rate <RATE> [OPTIONS]
```

### **3. Arguments & Default Parameters**

The following parameters control the mixing process and define the input datasets.

| Argument | Variable | Default | Description |
| :--- | :--- | :--- | :--- |
| `--known` | `KNOWN` | `MDS2c` | Tag of the pre-existing background ensemble (e.g., from Stage 2). |
| `--signal` | `SIGNAL` | `CeMLeadingLog` | Name of the signal Monte Carlo sample (e.g., $e^-$-CE leading log). |
| `--rate` | `RATE` | $1 \times 10^{-13}$ | The hypothesized $\mathbf{R}_{\mu \mathbf{e}}$ conversion rate to use for sampling the signal yield. |
| `--nexp` | `NEXP` | $1$ | **Number of Pseudo-Experiments:** How many mixed samples to create. |
| `--chooselivetime` | `CHOOSE` | $0$ | Optional: Manually set a smaller live time (in seconds) to subsample the background ensemble. |
| `--release` | `RELEASE` | `MDC2020ba` | The Mu2e software release tag. |
| `--dbpurpose` | `DBPURPOSE` | `best` | Database purpose for input files (e.g., `best` or `perfect`). |
| `--dbversion` | `DBVERSION` | `v1_3` | Database version tag. |
| `--owner` | `OWNER` | `mu2e` | The dataset owner. |

---

### **4. Execution Flow**

The script's core function is to calculate the precise number of signal and background files needed to match the requested live time and $R_{\mu e}$ rate for $N$ pseudo-experiments.

#### **Phase A: Load Configuration & Determine Live Time**

1.  **Retrieve Stage 2 Config:** The script reads the configuration file (`${KNOWN}.txt`) generated by Stage 1/2 to extract the original `GEN_LIVETIME` and `BB` (Beam Batch) mode of the background sample.

2.  **Live Time Adjustment:**
    * If `--chooselivetime` (`CHOOSE`) is set, the script overrides the original `LIVETIME`.
    * It calculates the number of background files (`N_KNOWN_FILES_TO_USE`) required to achieve this live time, based on the `LIVETIME_PER_FILE` of the original ensemble.
    * The `LIVETIME` is then fixed to the total live time contained in this integer number of background files.

3.  **Log Combined Sample Info:** Appends the final chosen `RATE`, `LIVETIME`, and `NEXP` to the configuration file for tracking.

#### **Phase B: Loop for Pseudo-Experiments**

The main logic runs in a `while [ $i -le ${NEXP} ]` loop, creating one mixed sample per iteration.

1.  **Calculate Signal Yield ($\mathbf{N}_{\mathbf{SIG}}$):**
    ```bash
    NSIG=$(calculateEvents.py --livetime ${LIVETIME} --prc ${SIGNAL} --BB ${BB} --rue ${RATE})
    ```
    The script uses `calculateEvents.py` to determine the mean expected number of signal events (`NSIG`) for the chosen $R_{\mu e}$ rate and the determined `LIVETIME`.

2.  **Calculate Required Signal Files:**
    The required number of signal events (`NSIG`) is converted into the number of signal files (`N_SIGNAL_FILES_TO_USE`) needed, based on the total generated events (`NGEN`) and total files (`N_TOTAL_SIGNAL`) in the raw signal MC sample.

3.  **Signal Splitting and Sampling:**
    * **Random File Selection:** `shuf -n ${N_SIGNAL_FILES_TO_USE}` randomly selects the required number of files from the master signal file list (`filenames_All_${SIGNAL}`).
    * **FCL Generation (`splitter_$i.fcl`):** A temporary FCL configuration is built that points to the randomly selected files.
    * **Event Splitting (`mu2e -c splitter_$i.fcl`):** The `mu2e` application is run with a special `split.fcl` module. This process reads the chosen files and creates a new, much smaller `.art` file containing *exactly* the calculated number of signal events (`NSIG`). 
    
4.  **Ntuple Production:**
    ```bash
    mu2e -c ntuple_$i.fcl mcs.<split_file>.art
    ```
    The newly split signal `.art` file is immediately processed to create a final analysis Ntuple (`nts.*.root`).

5.  **Background Mixing List:**
    ```bash
    shuf -n ${N_KNOWN_FILES_TO_USE} filenames_All_${KNOWN} >> temp
    shuf temp > filenames_ChosenMixed_$i
    ```
    The required number of background Ntuples (`N_KNOWN_FILES_TO_USE`) are randomly selected from the master background list and combined with the newly created signal Ntuple, forming the final list of files for the $i$-th pseudo-experiment.
    
    
## ðŸ”— Combining Ntuples `combine_ntuples.sh`

### **1. Overview**

This utility script is designed to run after `Stage3_addsignal.sh`. It takes the long list of randomly chosen individual background Ntuples and the newly generated signal Ntuple for a single pseudo-experiment (PE) and merges them into a smaller, more manageable set for final analysis.

| Component | Description |
| :--- | :--- |
| **Purpose** | To perform a sequential merge of analysis Ntuples (`.root` files) from a single pseudo-experiment using the ROOT utility `hadd`, creating a condensed final dataset for analysis. |
| **Input** | A list of Ntuple files (`filenames_ChosenMixed_$i`) generated in Stage 3, and the configuration file (`${KNOWN}.txt`). |
| **Tool Used** | `hadd` (ROOT Histo Adder) â€“ a utility specifically designed for merging ROOT files while preserving their data structures.  |
| **Outcome** | A single output directory (`merged_files_$i`) containing one or more merged Ntuple files, plus a list file (`merged_list_$i.txt`) tracking the merged files. |

### **2. Usage**

The script takes two positional arguments: the iteration number (`i`) of the pseudo-experiment and the known background tag (`KNOWN`).

```
combine_ntuples.sh <pseudo_experiment_iteration> <known_background_tag>
```

### **3. Parameter Extraction**

The script first reads key parameters from the Stage 3 configuration file (`${KNOWN}.txt`) to correctly name the output merged files:

| Variable | Source from Config | Description |
| :--- | :--- | :--- |
| `LIVETIME` | `livetime_combined` | The final effective live time of the merged sample. |
| `RMUE` | `Rmue` | The $R_{\mu e}$ conversion rate used to inject the signal. |
| `SIGNAL` | `signal` | The name of the injected signal (e.g., `CeMLeadingLog`). |
| `BB` | `BB` | The Beam Batch mode (`1BB` or `2BB`). |

The full output file name is constructed using all these parameters:
$$
\text{OUTNAME} = \text{nts.mu2e.ensemble}\mathbf{KNOWN}\text{Mix}\mathbf{BB}\_\mathbf{SIGNAL}\_\mathbf{RMUE}\_\mathbf{LIVETIME}.\mathbf{i}
$$

### **4. Merge Execution**

The core logic uses the **ROOT `hadd` utility** to merge files in batches for efficiency. 

1.  **Input File List:** The script reads the list of Ntuples to be merged from the file `filenames_ChosenMixed_$i` (created in Stage 3), which contains the mixed background and signal Ntuples for the current iteration.

2.  **Batch Processing:**
    * The variable `FILES_PER_MERGE` (set to `2` in the script) defines how many individual Ntuples are grouped together for a single `hadd` call.
    * The script iterates through the input list, accumulating files into the `file_group` array.

3.  **Hadd Command:** When the `file_group` array reaches `FILES_PER_MERGE`, the merge is executed:
    ```bash
    hadd -f "$output_filename" "${file_group[@]}"
    ```
    * `-f`: Forces overwriting of the output file if it exists.
    * `"${file_group[@]}"`: The list of input Ntuples to merge.

4.  **Output Tracking:**
    * Merged files are placed into a dedicated directory: `merged_files_$i`.
    * The name of each resulting merged file is written to `merged_list_$i.txt`.

5.  **Final Group Merge:** The script contains a check to ensure that any remaining files in the last, incomplete batch are also merged and accounted for.
